# core/tesst.py
# -*- coding: utf-8 -*-
import os
import sys
import json
import argparse
from pathlib import Path
from typing import List, Dict, Any

# ==== Ensure project root on sys.path (ƒë·ªÉ import core.*, models.*) ====
THIS_FILE = Path(__file__).resolve()
PROJECT_ROOT = THIS_FILE.parents[1]  # .../RAG_CHINH_full_topping
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

# ==== (T√πy ch·ªçn) ch·ªâ ƒë·ªãnh th∆∞ m·ª•c model fine-tune n·∫øu b·∫°n ƒë·ªÉ v·ªã tr√≠ kh√°c ====
DEFAULT_RERANKER_DIR = PROJECT_ROOT / "model_fine_turn_0.4" / "model" / "reranker_food_attr" / "best"
os.environ.setdefault("FOOD_RERANKER_DIR", str(DEFAULT_RERANKER_DIR))
os.environ.setdefault("FOOD_RERANKER_MAX_LEN", "224")

# ==== Imports sau khi ƒë√£ th√™m sys.path ====
from core.rag_system import rag_system
from models.ai_models import ai_models
from models.data_models import VietnameseDish
from config.settings import settings

# (Optional) load Excel seed
def try_load_excel(path: str) -> List[VietnameseDish]:
    """
    ƒê·ªçc Excel v√† chu·∫©n h√≥a 1 s·ªë tr∆∞·ªùng s·ªë (calories/fat/sugar/protein/cook_time/price) v·ªÅ int n·∫øu c√≥ th·ªÉ.
    """
    try:
        from utils.excel_loader import load_dishes_from_excel
        dishes = load_dishes_from_excel(path)

        # Chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu (an to√†n cho filter s·ªë)
        def _to_int(x):
            try:
                return int(str(x).replace(".", "").replace(",", "").strip())
            except Exception:
                return x

        for d in dishes:
            # nh·ªØng field n√†y th∆∞·ªùng l√† s·ªë
            if hasattr(d, "calories"):
                d.calories = _to_int(getattr(d, "calories", None))
            if hasattr(d, "fat"):
                d.fat = _to_int(getattr(d, "fat", None))
            if hasattr(d, "fiber"):
                d.fiber = _to_int(getattr(d, "fiber", None))
            if hasattr(d, "sugar"):
                d.sugar = _to_int(getattr(d, "sugar", None))
            if hasattr(d, "protein"):
                d.protein = _to_int(getattr(d, "protein", None))
            if hasattr(d, "cook_time"):
                d.cook_time = _to_int(getattr(d, "cook_time", None))
            if hasattr(d, "price"):
                d.price = _to_int(getattr(d, "price", None))

        if dishes:
            print(f"[INFO] Loaded {len(dishes)} dishes from Excel: {path}")
            return dishes
    except Exception as e:
        print(f"[WARN] Cannot load Excel '{path}': {e}")
    return []

def ensure_models():
    print(f"[INFO] Project root: {PROJECT_ROOT}")
    print(f"[INFO] FOOD_RERANKER_DIR = {os.environ.get('FOOD_RERANKER_DIR')}")
    ok = ai_models.initialize_models()
    if not ok:
        raise RuntimeError("Kh√¥ng kh·ªüi t·∫°o ƒë∆∞·ª£c ai_models (LLM / embeddings / vectorstore).")

def init_rag(dishes: List[VietnameseDish]):
    ok = rag_system.initialize(dishes)
    if not ok:
        raise RuntimeError("RAG initialize failed. Ki·ªÉm tra l·∫°i ai_models & c·∫•u h√¨nh.")
    # k√≠ch ho·∫°t lazy reranker
    _ = rag_system.search_relevant_dishes("ping reranker")

def pretty_print_results(q: str, k_print: int = 5):
    res = rag_system.search_relevant_dishes(q)
    stats = rag_system.get_statistics()
    reranker_loaded = stats["search_config"].get("reranker_loaded")
    print(f"Reranker loaded? -> {reranker_loaded}")
    if not res:
        print("[WARN] Kh√¥ng c√≥ k·∫øt qu·∫£. H√£y ki·ªÉm tra embeddings, retriever ho·∫∑c d·ªØ li·ªáu.")
        return
    for r in res[:k_print]:
        print(f"- {r.dish.name} | score={getattr(r, 'score', None)} | reason={getattr(r, 'relevance','')}")
    print("\n===== CONTEXT =====")
    print(rag_system.get_context_for_llm(q))

def _strict_template_from_results(results) -> str:
    """Sinh context ng·∫Øn g·ªçn, ch·ªâ g·ªìm c√°c m√≥n h·ª£p l·ªá (t·ª´ RAG)."""
    lines = []
    for i, r in enumerate(results, 1):
        d = r.dish
        desc = (d.description or "").strip()
        if len(desc) > 160:
            desc = desc[:160] + "..."
        lines.append(
            f"{i}. {d.name} ‚Äî v√πng: {d.region or 'N/A'}; t√≠nh ch·∫•t: {getattr(d, 'texture','') or 'N/A'}; "
            f"lo·∫°i: {getattr(d, 'dish_type','') or 'N/A'}; th·ªùi gian: {getattr(d, 'cook_time','') or 'N/A'}; "
            f"gi√°: {getattr(d, 'price','') or 'N/A'}; m√¥ t·∫£: {desc}"
        )
    return "\n".join(lines)

def answer_with_llm_free(query: str):
    """Ch·∫ø ƒë·ªô t·ª± do (c√≥ th·ªÉ b·ªãa) ‚Äì gi·ªØ l·∫°i ƒë·ªÉ so s√°nh."""
    ctx = rag_system.get_context_for_llm(query)
    llm = ai_models.get_llm()

    system_msg = (
        "B·∫°n l√† tr·ª£ l√Ω nh√† h√†ng Vi·ªát, tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c. "
        "Ch·ªâ d·ª±a tr√™n NG·ªÆ C·∫¢NH cung c·∫•p; n·∫øu thi·∫øu th√¥ng tin th√¨ n√≥i ch∆∞a r√µ, kh√¥ng b·ªãa."
    )
    user_msg = (
        f"C√¢u h·ªèi: {query}\n\n"
        f"NG·ªÆ C·∫¢NH (t·ª´ RAG):\n{ctx}\n\n"
        "H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, li·ªát k√™ m√≥n ph√π h·ª£p (n·∫øu c√≥) v√† gi·∫£i th√≠ch ng·∫Øn g·ªçn."
    )

    try:
        result = llm.invoke([("system", system_msg), ("human", user_msg)])
        text = getattr(result, "content", None) or str(result)
    except Exception as e:
        text = f"[LLM ERROR] {e}"

    print("\n===== LLM ANSWER (FREE) =====")
    print(text)
    print("==================================\n")

def answer_with_llm_strict(query: str, top_k: int = 5):
    """
    Ch·∫ø ƒë·ªô STRICT:
    - L·∫•y top-k m√≥n t·ª´ RAG.
    - B·∫Øt LLM ch·ªâ ƒë∆∞·ª£c ch·ªçn trong danh s√°ch cho ph√©p (allowed_names).
    - Y√™u c·∫ßu output JSON c√≥ c·∫•u tr√∫c, r·ªìi h·∫≠u ki·ªÉm.
    - N·∫øu kh√¥ng c√≤n m√≥n h·ª£p l·ªá => fallback in th·∫≥ng top-k t·ª´ RAG, KH√îNG b·ªãa.
    """
    results = rag_system.search_relevant_dishes(query)
    if not results:
        print("\n===== STRICT ANSWER =====")
        print("Kh√¥ng t√¨m th·∫•y m√≥n ph√π h·ª£p trong d·ªØ li·ªáu. Vui l√≤ng h·ªèi kh√°c ho·∫∑c ki·ªÉm tra data.")
        print("==================================\n")
        return

    results = results[:top_k]
    allowed_names = [r.dish.name for r in results]

    compact_ctx = _strict_template_from_results(results)
    llm = ai_models.get_llm()

    system_msg = (
        "B·∫°n l√† tr·ª£ l√Ω nh√† h√†ng Vi·ªát. TUY·ªÜT ƒê·ªêI kh√¥ng ƒë∆∞·ª£c n√™u m√≥n ngo√†i danh s√°ch cho ph√©p. "
        "Ch·ªâ ƒë∆∞·ª£c ch·ªçn t·ª´ 'allowed_names'. N·∫øu kh√¥ng ph√π h·ª£p, tr·∫£ v·ªÅ m·∫£ng r·ªóng."
    )
    user_msg = (
        "Nhi·ªám v·ª•: Ch·ªçn 1-5 m√≥n ph√π h·ª£p nh·∫•t cho c√¢u h·ªèi ph√≠a d∆∞·ªõi, "
        "NH∆ØNG ch·ªâ ƒë∆∞·ª£c ch·ªçn t·ª´ allowed_names.\n\n"
        f"C√¢u h·ªèi: {query}\n\n"
        "NG·ªÆ C·∫¢NH r√∫t g·ªçn (RAG top-k):\n"
        f"{compact_ctx}\n\n"
        f"allowed_names = {json.dumps(allowed_names, ensure_ascii=False)}\n\n"
        "H√£y tr·∫£ l·ªùi ƒë√∫ng **ƒë·ªãnh d·∫°ng JSON** sau (KH√îNG th√™m ch·ªØ, KH√îNG markdown):\n"
        '{\n'
        '  "picks": [\n'
        '    {"name": "<t√™n m√≥n trong allowed_names>", "why": "<l√Ω do ng·∫Øn g·ªçn>"}\n'
        '  ]\n'
        '}\n'
        "N·∫øu kh√¥ng c√≥ m√≥n n√†o ph√π h·ª£p, tr·∫£ v·ªÅ: {\"picks\": []}"
    )

    raw_text = ""
    try:
        result = llm.invoke([("system", system_msg), ("human", user_msg)])
        raw_text = getattr(result, "content", None) or str(result)
    except Exception as e:
        raw_text = f'{{"error":"LLM ERROR: {e}"}}'

    valid_picks: List[Dict[str, Any]] = []
    try:
        data = json.loads(raw_text)
        for item in data.get("picks", []):
            name = (item.get("name") or "").strip()
            why = (item.get("why") or "").strip()
            if name in allowed_names:
                valid_picks.append({"name": name, "why": why})
    except Exception:
        valid_picks = []

    print("\n===== LLM ANSWER (STRICT) =====")
    if valid_picks:
        for i, p in enumerate(valid_picks, 1):
            print(f"{i}. {p['name']} ‚Äî {p['why']}")
    else:
        print("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c l·ª±a ch·ªçn h·ª£p l·ªá t·ª´ LLM, hi·ªÉn th·ªã g·ª£i √Ω t·ª´ RAG (an to√†n):")
        for i, r in enumerate(results, 1):
            d = r.dish
            reason_hint = (d.description or "").strip()
            if len(reason_hint) > 120:
                reason_hint = reason_hint[:120] + "..."
            print(f"{i}. {d.name} ‚Äî ph√π h·ª£p v√¨ g·∫ßn truy v·∫•n; {reason_hint}")
    print("==================================\n")

def run_repl(mode: str):
    print("\nüß™ REPL test ‚Äî g√µ c√¢u h·ªèi tr·ª±c ti·∫øp ho·∫∑c d√πng l·ªánh:")
    print("  :ask <c√¢u h·ªèi>     ‚Üí RAG + LLM (theo mode b·∫°n ch·ªçn)")
    print("  :search <c√¢u h·ªèi>  ‚Üí Ch·ªâ t√¨m ki·∫øm & hi·ªÉn th·ªã top k·∫øt qu·∫£ + context")
    print("  :ctx <c√¢u h·ªèi>     ‚Üí In ri√™ng NG·ªÆ C·∫¢NH (context) t·ª´ RAG")
    print("  :stats             ‚Üí In th·ªëng k√™ RAG")
    print("  :exit              ‚Üí Tho√°t\n")

    while True:
        try:
            q = input(">>> ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nBye!")
            break

        if not q:
            continue
        if q.lower() in (":exit", ":quit"):
            print("Bye!")
            break
        if q.lower().startswith(":stats"):
            print(rag_system.get_statistics())
            continue
        if q.lower().startswith(":ctx"):
            rest = q[len(":ctx"):].strip()
            if not rest:
                print("C√∫ ph√°p: :ctx <c√¢u h·ªèi>")
            else:
                print("\n===== CONTEXT =====")
                print(rag_system.get_context_for_llm(rest))
                print("===================\n")
            continue
        if q.lower().startswith(":search"):
            rest = q[len(":search"):].strip()
            if not rest:
                print("C√∫ ph√°p: :search <c√¢u h·ªèi>")
            else:
                pretty_print_results(rest)
            continue
        if q.lower().startswith(":ask"):
            rest = q[len(":ask"):].strip()
            if not rest:
                print("C√∫ ph√°p: :ask <c√¢u h·ªèi>")
            else:
                if mode == "strict":
                    answer_with_llm_strict(rest)
                else:
                    answer_with_llm_free(rest)
            continue

        if mode == "strict":
            answer_with_llm_strict(q)
        else:
            answer_with_llm_free(q)

def main():
    parser = argparse.ArgumentParser(description="Tester cho RAG & RAG+LLM (STRICT m·∫∑c ƒë·ªãnh)")
    parser.add_argument("--excel", type=str, default="", help="ƒê∆∞·ªùng d·∫´n file Excel (data100mon.xlsx)")
    parser.add_argument("--ask", type=str, default="", help="H·ªèi m·ªôt c√¢u r·ªìi tho√°t (RAG+LLM)")
    parser.add_argument("--search", type=str, default="", help="Ch·ªâ t√¨m ki·∫øm & in context r·ªìi tho√°t")
    parser.add_argument("--mode", type=str, choices=["strict", "free"], default="strict",
                        help="strict: ch·ªâ ch·ªçn trong top-k t·ª´ RAG; free: ƒë·ªÉ LLM t·ª± do")
    parser.add_argument("--topk", type=int, default=5, help="S·ªë ·ª©ng vi√™n RAG chuy·ªÉn cho LLM (strict)")
    args = parser.parse_args()

    ensure_models()

    # ==== N·∫°p d·ªØ li·ªáu Excel th·∫≠t ====
    excel_path = (
        args.excel.strip()
        or settings.DATA_FILE_PATH
        or str(PROJECT_ROOT / "data100mon.xlsx")
    )
    dishes: List[VietnameseDish] = try_load_excel(excel_path)
    if not dishes:
        raise SystemExit(
            f"[FATAL] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c d·ªØ li·ªáu t·ª´ Excel. "
            f"Th·ª≠ ch·∫°y l·∫°i v·ªõi --excel <ƒë∆∞·ªùng_d·∫´n_t·ªõi_data100mon.xlsx>. "
            f"ƒêang d√πng: {excel_path}"
        )

    init_rag(dishes)

    # One-shot modes
    if args.ask:
        if args.mode == "strict":
            answer_with_llm_strict(args.ask, top_k=args.topk)
        else:
            answer_with_llm_free(args.ask)
        return
    if args.search:
        pretty_print_results(args.search)
        return

    # REPL
    run_repl(args.mode)

if __name__ == "__main__":
    main()
